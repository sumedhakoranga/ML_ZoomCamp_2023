{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWqpVU2A7YZ5GFJBxedpq3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumedhakoranga/ML_ZoomCamp_2023/blob/main/ML_ZoomCamp_Session10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework\n",
        "\n",
        "In this homework, we'll deploy the credit scoring model from the homework 5.\n",
        "We already have a docker image for this model - we'll use it for\n",
        "deploying the model to Kubernetes.\n"
      ],
      "metadata": {
        "id": "SJcOhLvnDG97"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U422F4hoDGvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulding the image\n",
        "\n",
        "Clone the course repo if you haven't:\n",
        "\n",
        "```\n",
        "git clone https://github.com/DataTalksClub/machine-learning-zoomcamp.git\n",
        "```\n",
        "\n",
        "Go to the `course-zoomcamp/cohorts/2023/05-deployment/homework` folder and\n",
        "execute the following:\n",
        "\n"
      ],
      "metadata": {
        "id": "kTz5tOaSDKxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "docker build -t zoomcamp-model:hw10 .\n",
        "```\n",
        "\n",
        "> **Note:** If you have troubles building the image, you can\n",
        "> use the image we built and published to docker hub:\n",
        "> `docker pull svizor/zoomcamp-model:hw10`\n"
      ],
      "metadata": {
        "id": "hBMfDrdQDLxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "\n",
        "Run it to test that it's working locally:\n",
        "\n",
        "```bash\n",
        "docker run -it --rm -p 9696:9696 zoomcamp-model:hw10\n",
        "```\n",
        "\n",
        "And in another terminal, execute `q6_test.py` file:\n",
        "\n",
        "```bash\n",
        "python q6_test.py\n",
        "```\n",
        "\n",
        "You should see this:\n",
        "\n",
        "```python\n",
        "{'get_credit': True, 'get_credit_probability': <value>}\n",
        "```"
      ],
      "metadata": {
        "id": "OEk8YlPaDORM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here `<value>` is the probability of getting a credit card. You need to choose the right one.\n",
        "\n",
        "* 0.3269\n",
        "* 0.5269\n",
        "* 0.7269\n",
        "* 0.9269\n",
        "\n",
        "Now you can stop the container running in Docker.\n"
      ],
      "metadata": {
        "id": "TJZBFn63DSzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "0.7269"
      ],
      "metadata": {
        "id": "5SmCH2IxDUt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc842461-00ba-4b9b-b2a7-42880cea145f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7269"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing `kubectl` and `kind`\n",
        "\n",
        "You need to install:\n",
        "\n",
        "* `kubectl` - https://kubernetes.io/docs/tasks/tools/ (you might already have it - check before installing)\n",
        "* `kind` - https://kind.sigs.k8s.io/docs/user/quick-start/\n",
        "\n"
      ],
      "metadata": {
        "id": "wiKrUkvxDVCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "\n",
        "What's the version of `kind` that you have?\n",
        "\n",
        "Use `kind --version` to find out."
      ],
      "metadata": {
        "id": "mkCZfJZCDy-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kind version 0.20.0"
      ],
      "metadata": {
        "id": "xJc24iOlDzVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a cluster\n",
        "\n",
        "Now let's create a cluster with `kind`:\n",
        "\n",
        "```bash\n",
        "kind create cluster\n",
        "```\n",
        "\n",
        "And check with `kubectl` that it was successfully created:\n",
        "\n",
        "```bash\n",
        "kubectl cluster-info\n",
        "```"
      ],
      "metadata": {
        "id": "dXOK-gkWDz47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "Now let's test if everything works. Use `kubectl` to get the list of running services.\n",
        "\n",
        "What's `CLUSTER-IP` of the service that is already running there?\n"
      ],
      "metadata": {
        "id": "6G1zftfqD2FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.96.96.8"
      ],
      "metadata": {
        "id": "2pY0ifnI0OD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "\n",
        "To be able to use the docker image we previously created (`zoomcamp-model:hw10`),\n",
        "we need to register it with `kind`.\n",
        "\n",
        "What's the command we need to run for that?\n",
        "\n",
        "* `kind create cluster`\n",
        "* `kind build node-image`\n",
        "* `kind load docker-image`\n",
        "* `kubectl apply`"
      ],
      "metadata": {
        "id": "byBhBWgED8fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kind load docker-image"
      ],
      "metadata": {
        "id": "CFzIAVFznjyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "\n",
        "Now let's create a deployment config (e.g. `deployment.yaml`):\n",
        "\n",
        "```yaml\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: credit\n",
        "spec:\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: credit\n",
        "  replicas: 1\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: credit\n",
        "    spec:\n",
        "      containers:\n",
        "      - name: credit\n",
        "        image: <Image>\n",
        "        resources:\n",
        "          requests:\n",
        "            memory: \"64Mi\"\n",
        "            cpu: \"100m\"            \n",
        "          limits:\n",
        "            memory: <Memory>\n",
        "            cpu: <CPU>\n",
        "        ports:\n",
        "        - containerPort: <Port>\n",
        "```\n",
        "\n",
        "Replace `<Image>`, `<Memory>`, `<CPU>`, `<Port>` with the correct values.\n",
        "\n",
        "What is the value for `<Port>`?"
      ],
      "metadata": {
        "id": "VBRU-MzlEFyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "443/TCP"
      ],
      "metadata": {
        "id": "kxqHa7CyFLRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply this deployment using the appropriate command and get a list of running Pods.\n",
        "You can see one running Pod."
      ],
      "metadata": {
        "id": "iAH_oPxQFL0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Let's create a service for this deployment (`service.yaml`):\n",
        "\n",
        "```yaml\n",
        "apiVersion: v1\n",
        "kind: Service\n",
        "metadata:\n",
        "  name: <Service name>\n",
        "spec:\n",
        "  type: LoadBalancer\n",
        "  selector:\n",
        "    app: <???>\n",
        "  ports:\n",
        "  - port: 80\n",
        "    targetPort: <PORT>\n",
        "```"
      ],
      "metadata": {
        "id": "R-I1QBnDFOle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill it in. What do we need to write instead of `<???>`?\n",
        "\n",
        "Apply this config file."
      ],
      "metadata": {
        "id": "DpQGiMVxFgS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the service\n",
        "\n",
        "We can test our service locally by forwarding the port 9696 on our computer\n",
        "to the port 80 on the service:\n",
        "\n",
        "```bash\n",
        "kubectl port-forward service/<Service name> 9696:80\n",
        "```\n",
        "\n",
        "Run `q6_test.py` (from the homework 5) once again to verify that everything is working.\n",
        "You should get the same result as in Question 1.\n"
      ],
      "metadata": {
        "id": "tW1HMCnGFk7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoscaling\n",
        "\n",
        "Now we're going to use a [HorizontalPodAutoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)\n",
        "(HPA for short) that automatically updates a workload resource (such as our deployment),\n",
        "with the aim of automatically scaling the workload to match demand.\n",
        "\n",
        "Use the following command to create the HPA:\n",
        "\n",
        "```bash\n",
        "kubectl autoscale deployment credit --name credit-hpa --cpu-percent=20 --min=1 --max=3\n",
        "```\n",
        "\n",
        "You can check the current status of the new HPA by running:\n",
        "\n",
        "```bash\n",
        "kubectl get hpa\n",
        "```\n",
        "\n",
        "The output should be similar to the next:\n",
        "\n",
        "```bash\n",
        "NAME              REFERENCE                TARGETS   MINPODS   MAXPODS   REPLICAS   AGE\n",
        "credit-hpa   Deployment/credit   1%/20%    1         3         1          27s\n",
        "```\n",
        "\n",
        "`TARGET` column shows the average CPU consumption across all the Pods controlled by the corresponding deployment.\n",
        "Current CPU consumption is about 0% as there are no clients sending requests to the server.\n",
        ">\n",
        ">Note: In case the HPA instance doesn't run properly, try to install the latest Metrics Server release\n",
        "> from the `components.yaml` manifest:\n",
        "> ```bash\n",
        "> kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n",
        ">```\n"
      ],
      "metadata": {
        "id": "1reqKociFnh6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmW4pC-TFqPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Increase the load\n",
        "\n",
        "Let's see how the autoscaler reacts to increasing the load. To do this, we can slightly modify the existing\n",
        "`q6_test.py` script by putting the operator that sends the request to the credit service into a loop.\n",
        "\n",
        "```python\n",
        "while True:\n",
        "    sleep(0.1)\n",
        "    response = requests.post(url, json=client).json()\n",
        "    print(response)\n",
        "```\n",
        "\n",
        "Now you can run this script.\n"
      ],
      "metadata": {
        "id": "K07ECk5VFqyE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S5C0cycjFtJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7 (optional)\n",
        "\n",
        "Run `kubectl get hpa credit-hpa --watch` command to monitor how the autoscaler performs.\n",
        "Within a minute or so, you should see the higher CPU load; and then - more replicas.\n",
        "What was the maximum amount of the replicas during this test?\n",
        "\n",
        "\n",
        "* 1\n",
        "* 2\n",
        "* 3\n",
        "* 4\n",
        "\n",
        "> Note: It may take a few minutes to stabilize the number of replicas. Since the amount of load is not controlled\n",
        "> in any way it may happen that the final number of replicas will differ from initial.\n",
        "\n"
      ],
      "metadata": {
        "id": "lWLkCpjVFtjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1"
      ],
      "metadata": {
        "id": "16ToIQ_ssRxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submit your results here: https://forms.gle/35gEVapd3uBoExFW7\n",
        "You can submit your solution multiple times. In this case, only the last submission will be used\n",
        "If your answer doesn't match options exactly, select the closest one\n",
        "Deadline\n",
        "The deadline for submitting is 4 December 2022 (Monday), 23:00 CET (Berlin time).\n",
        "\n",
        "After that, the form will be closed."
      ],
      "metadata": {
        "id": "7V-axUMG54cv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPkZ4SEx543x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
